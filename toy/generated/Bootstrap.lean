/-
  Generated from Bootstrap.lego

  This module was automatically generated by ToLean.
  It should be structurally equivalent to hand-written Bootstrap.lean.
-/

import Lego.Algebra
import Lego.Interp

namespace Lego.Bootstrap

open GrammarExpr

/-! ## Grammar Pieces -/

/-- Token piece -/
def tokenPiece : Piece := {
  name := "Token"
  grammar := [
    ("Token.digit", ((lit "'0'").alt ((lit "'1'").alt ((lit "'2'").alt ((lit "'3'").alt ((lit "'4'").alt ((lit "'5'").alt ((lit "'6'").alt ((lit "'7'").alt ((lit "'8'").alt (lit "'9'"))))))))))),
    ("Token.lower", ((lit "'a'").alt ((lit "'b'").alt ((lit "'c'").alt ((lit "'d'").alt ((lit "'e'").alt ((lit "'f'").alt ((lit "'g'").alt ((lit "'h'").alt ((lit "'i'").alt ((lit "'j'").alt ((lit "'k'").alt ((lit "'l'").alt ((lit "'m'").alt ((lit "'n'").alt ((lit "'o'").alt ((lit "'p'").alt ((lit "'q'").alt ((lit "'r'").alt ((lit "'s'").alt ((lit "'t'").alt ((lit "'u'").alt ((lit "'v'").alt ((lit "'w'").alt ((lit "'x'").alt ((lit "'y'").alt (lit "'z'"))))))))))))))))))))))))))),
    ("Token.upper", ((lit "'A'").alt ((lit "'B'").alt ((lit "'C'").alt ((lit "'D'").alt ((lit "'E'").alt ((lit "'F'").alt ((lit "'G'").alt ((lit "'H'").alt ((lit "'I'").alt ((lit "'J'").alt ((lit "'K'").alt ((lit "'L'").alt ((lit "'M'").alt ((lit "'N'").alt ((lit "'O'").alt ((lit "'P'").alt ((lit "'Q'").alt ((lit "'R'").alt ((lit "'S'").alt ((lit "'T'").alt ((lit "'U'").alt ((lit "'V'").alt ((lit "'W'").alt ((lit "'X'").alt ((lit "'Y'").alt (lit "'Z'"))))))))))))))))))))))))))),
    ("Token.greek", ((lit "'α'").alt ((lit "'β'").alt ((lit "'γ'").alt ((lit "'δ'").alt ((lit "'ε'").alt ((lit "'ζ'").alt ((lit "'η'").alt ((lit "'θ'").alt ((lit "'ι'").alt ((lit "'κ'").alt ((lit "'λ'").alt ((lit "'μ'").alt ((lit "'ν'").alt ((lit "'ξ'").alt ((lit "'ο'").alt ((lit "'π'").alt ((lit "'ρ'").alt ((lit "'σ'").alt ((lit "'τ'").alt ((lit "'υ'").alt ((lit "'φ'").alt ((lit "'χ'").alt ((lit "'ψ'").alt ((lit "'ω'").alt ((lit "'Α'").alt ((lit "'Β'").alt ((lit "'Γ'").alt ((lit "'Δ'").alt ((lit "'Ε'").alt ((lit "'Ζ'").alt ((lit "'Η'").alt ((lit "'Θ'").alt ((lit "'Ι'").alt ((lit "'Κ'").alt ((lit "'Λ'").alt ((lit "'Μ'").alt ((lit "'Ν'").alt ((lit "'Ξ'").alt ((lit "'Ο'").alt ((lit "'Π'").alt ((lit "'Ρ'").alt ((lit "'Σ'").alt ((lit "'Τ'").alt ((lit "'Υ'").alt ((lit "'Φ'").alt ((lit "'Χ'").alt ((lit "'Ψ'").alt (lit "'Ω'"))))))))))))))))))))))))))))))))))))))))))))))))),
    ("Token.alpha", ((ref "Token.lower").alt ((ref "Token.upper").alt ((ref "Token.greek").alt (lit "'_'"))))),
    ("Token.symch", ((lit "'('").alt ((lit "')'").alt ((lit "'['").alt ((lit "']'").alt ((lit "'{'").alt ((lit "'}'").alt ((lit "'<'").alt ((lit "'>'").alt ((lit "':'").alt ((lit "';'").alt ((lit "','").alt ((lit "'.'").alt ((lit "'|'").alt ((lit "'!'").alt ((lit "'?'").alt ((lit "'@'").alt ((lit "'#'").alt ((lit "'$'").alt ((lit "'%'").alt ((lit "'^'").alt ((lit "'&'").alt ((lit "'*'").alt ((lit "'+'").alt ((lit "'-'").alt ((lit "'='").alt ((lit "'~'").alt ((lit "'/'").alt ((lit "'\\\\'").alt ((lit "'→'").alt ((lit "'←'").alt ((lit "'↔'").alt (lit "'⊕'"))))))))))))))))))))))))))))))))),
    ("Token.ident", ((ref "Token.alpha").seq (((ref "Token.alpha").alt (ref "Token.digit")).star))),
    ("Token.number", ((ref "Token.digit").seq ((ref "Token.digit").star))),
    ("Token.string", (((lit "'\"'").seq ((ref "Token.strchar").star)).seq (lit "'\"'"))),
    ("Token.strchar", (((empty.seq (lit "'\\\\'")).seq (ref "Token.escape")).alt (ref "Token.printable"))),
    ("Token.escape", ((lit "'\"'").alt ((lit "'\\\\'").alt ((lit "'n'").alt ((lit "'t'").alt (lit "'r'")))))),
    ("Token.printable", ((ref "Token.alpha").alt ((ref "Token.digit").alt ((ref "Token.symch").alt (lit "' '")))))
  ]
  rules := []
}

/-- Atom piece -/
def atomPiece : Piece := {
  name := "Atom"
  grammar := [
    ("Atom.ident", (node "ident" (ref "TOKEN.ident"))),
    ("Atom.string", (node "string" (ref "TOKEN.string"))),
    ("Atom.char", (node "char" (ref "TOKEN.char"))),
    ("Atom.number", (node "number" (ref "TOKEN.number")))
  ]
  rules := []
}

/-- Term piece -/
def termPiece : Piece := {
  name := "Term"
  grammar := [
    ("Term.term", ((node "var" (ref "Atom.ident")).alt ((node "lit" (ref "Atom.string")).alt ((node "num" (ref "Atom.number")).alt (node "con" ((((lit "(").seq (ref "Term.conname")).seq ((ref "Term.term").star)).seq (lit ")"))))))),
    ("Term.conname", (ref "Atom.ident"))
  ]
  rules := []
}

/-- Pattern piece -/
def patternPiece : Piece := {
  name := "Pattern"
  grammar := [
    ("Pattern.pattern", ((node "var" ((lit "$").seq (ref "Atom.ident"))).alt ((node "con" ((((lit "(").seq (ref "Term.conname")).seq ((ref "Pattern.pattern").star)).seq (lit ")"))).alt ((node "lit" (ref "Atom.string")).alt (node "con" (ref "Atom.ident"))))))
  ]
  rules := []
}

/-- Template piece -/
def templatePiece : Piece := {
  name := "Template"
  grammar := [
    ("Template.template", ((node "var" ((lit "$").seq (ref "Atom.ident"))).alt ((node "con" ((((lit "(").seq (ref "Atom.ident")).seq ((ref "Template.template").star)).seq (lit ")"))).alt ((node "lit" (ref "Atom.string")).alt (node "con" (ref "Atom.ident"))))))
  ]
  rules := []
}

/-- GrammarExpr piece -/
def grammarExprPiece : Piece := {
  name := "GrammarExpr"
  grammar := [
    ("GrammarExpr.expr", (ref "GrammarExpr.alt")),
    ("GrammarExpr.alt", ((node "alt" (((ref "GrammarExpr.seq").seq (lit "|")).seq (ref "GrammarExpr.alt"))).alt (ref "GrammarExpr.seq"))),
    ("GrammarExpr.seq", ((node "annotated" (((ref "GrammarExpr.seqBase").seq (lit "→")).seq (ref "Atom.ident"))).alt (ref "GrammarExpr.seqBase"))),
    ("GrammarExpr.seqBase", ((node "seq" ((ref "GrammarExpr.suffix").seq ((ref "GrammarExpr.suffix").star))).alt (ref "GrammarExpr.suffix"))),
    ("GrammarExpr.suffix", ((node "star" ((ref "GrammarExpr.atom").seq (lit "*"))).alt ((node "plus" ((ref "GrammarExpr.atom").seq (lit "+"))).alt ((node "opt" ((ref "GrammarExpr.atom").seq (lit "?"))).alt (ref "GrammarExpr.atom"))))),
    ("GrammarExpr.atom", ((node "lit" (ref "Atom.string")).alt ((node "chr" (ref "Atom.char")).alt ((node "ref" (ref "Atom.ident")).alt ((node "group" (((lit "(").seq (ref "GrammarExpr.expr")).seq (lit ")"))).alt ((node "special" (ref "TOKEN.special")).alt (node "empty" (lit "ε"))))))))
  ]
  rules := []
}

/-- File piece -/
def filePiece : Piece := {
  name := "File"
  grammar := [
    ("File.legoFile", ((ref "File.decl").star)),
    ("File.decl", ((ref "File.importDecl").alt ((ref "File.langDecl").alt ((ref "File.tokenDecl").alt ((ref "File.pieceDecl").alt ((ref "File.ruleDecl").alt (ref "File.testDecl"))))))),
    ("File.importDecl", (node "DImport" (((lit "import").seq (ref "Atom.ident")).seq (lit ";")))),
    ("File.langDecl", (node "DLang" (((((lit "lang").seq (ref "Atom.ident")).seq ((ref "File.imports").alt empty)).seq (lit ":=")).seq (ref "File.langBody")))),
    ("File.imports", (node "DImports" ((((lit "(").seq (ref "Atom.ident")).seq (((lit ",").seq (ref "Atom.ident")).star)).seq (lit ")")))),
    ("File.langBody", ((ref "File.innerDecl").star)),
    ("File.innerDecl", ((ref "File.tokenDecl").alt ((ref "File.pieceDecl").alt ((ref "File.ruleDecl").alt (ref "File.testDecl"))))),
    ("File.tokenDecl", (node "DToken" (((lit "token").seq (ref "Atom.ident")).seq ((ref "File.prodDecl").seq ((ref "File.prodDecl").star))))),
    ("File.pieceDecl", (node "DPiece" (((lit "piece").seq (ref "Atom.ident")).seq ((ref "File.prodDecl").seq ((ref "File.prodDecl").star))))),
    ("File.prodDecl", (node "DGrammar" ((((ref "Atom.ident").seq (lit "::=")).seq (ref "GrammarExpr.expr")).seq (lit ";")))),
    ("File.ruleDecl", (node "DRule" (((((((lit "rule").seq (ref "Atom.ident")).seq (lit ":")).seq (ref "Pattern.pattern")).seq (lit "~>")).seq (ref "Template.template")).seq (lit ";")))),
    ("File.testDecl", (node "DTest" ((((((lit "test").seq (ref "Atom.string")).seq (lit ":")).seq (ref "Term.term")).seq (((lit "~~>").seq (ref "Term.term")).alt empty)).seq (lit ";"))))
  ]
  rules := []
}

/-! ## Language Definition -/

/-- The complete Bootstrap language -/
def grammar : Language := {
  name := "Bootstrap"
  pieces := [tokenPiece, atomPiece, termPiece, patternPiece, templatePiece, grammarExprPiece, filePiece]
}

/-- Build the interpreter -/
def interp : LangInterp := grammar.toInterp "File.legoFile"

/-! ## Tokenizer -/
/-- Check if character is in Digit set -/
def isDigit (c : Char) : Bool :=
  c ∈ ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']

/-- Check if character is in Lower set -/
def isLower (c : Char) : Bool :=
  c ∈ ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']

/-- Check if character is in Upper set -/
def isUpper (c : Char) : Bool :=
  c ∈ ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']

/-- Check if character is in Greek set -/
def isGreek (c : Char) : Bool :=
  c ∈ ['α', 'β', 'γ', 'δ', 'ε', 'ζ', 'η', 'θ', 'ι', 'κ', 'λ', 'μ', 'ν', 'ξ', 'ο', 'π', 'ρ', 'σ', 'τ', 'υ', 'φ', 'χ', 'ψ', 'ω', 'Α', 'Β', 'Γ', 'Δ', 'Ε', 'Ζ', 'Η', 'Θ', 'Ι', 'Κ', 'Λ', 'Μ', 'Ν', 'Ξ', 'Ο', 'Π', 'Ρ', 'Σ', 'Τ', 'Υ', 'Φ', 'Χ', 'Ψ', 'Ω']

/-- Check if character is in Alpha set -/
def isAlpha (c : Char) : Bool :=
  c ∈ ['_']

/-- Check if character is in Symch set -/
def isSymch (c : Char) : Bool :=
  c ∈ ['(', ')', '[', ']', '{', '}', '<', '>', ':', ';', ',', '.', '|', '!', '?', '@', '#', '$', '%', '^', '&', '*', '+', '-', '=', '~', '/', '→', '←', '↔', '⊕']

/-- Check if character is in String set -/
def isString (c : Char) : Bool :=
  c ∈ ['"']

/-- Check if character is in Escape set -/
def isEscape (c : Char) : Bool :=
  c ∈ ['"', 'n', 't', 'r']

/-- Check if character is in Printable set -/
def isPrintable (c : Char) : Bool :=
  c ∈ [' ']

/-- Tokenize a string into tokens -/
partial def tokenize (s : String) : TokenStream :=
  let lines := s.splitOn "\n" |>.map String.trim |>.filter (· ≠ "")
  lines.foldl (fun acc line => acc ++ tokenizeLine line.toList []) []
where
  tokenizeLine (chars : List Char) (acc : List Token) : TokenStream :=
    match chars with
    | [] => acc.reverse
    | c :: rest =>
      if c.isWhitespace then
        tokenizeLine rest acc
      else if c == '"' then
        let (str, rest') := takeString rest ""
        tokenizeLine rest' (Token.lit s!"\"{str}\"" :: acc)
      else if c == '\'' then
        let (chr, rest') := takeChar rest
        tokenizeLine rest' (Token.lit s!"'{chr}'" :: acc)
      else if c.isAlpha || c == '_' then
        let (ident, rest') := takeIdent chars ""
        tokenizeLine rest' (Token.ident ident :: acc)
      else if c.isDigit then
        let (num, rest') := takeNumber chars ""
        tokenizeLine rest' (Token.number num :: acc)
      else
        tokenizeLine rest (Token.sym (String.singleton c) :: acc)

  takeString (chars : List Char) (acc : String) : String × List Char :=
    match chars with
    | [] => (acc, [])
    | '"' :: rest => (acc, rest)
    | '\\' :: c :: rest => takeString rest (acc.push '\\' |>.push c)
    | c :: rest => takeString rest (acc.push c)

  takeChar (chars : List Char) : String × List Char :=
    match chars with
    | [] => ("", [])
    | c :: '\'' :: rest => (String.singleton c, rest)
    | _ => ("", chars)

  takeIdent (chars : List Char) (acc : String) : String × List Char :=
    match chars with
    | [] => (acc, [])
    | c :: rest =>
      if c.isAlpha || c.isDigit || c == '_' then
        takeIdent rest (acc.push c)
      else (acc, chars)

  takeNumber (chars : List Char) (acc : String) : String × List Char :=
    match chars with
    | [] => (acc, [])
    | c :: rest =>
      if c.isDigit then takeNumber rest (acc.push c)
      else (acc, chars)

/-- Parse input -/
def parse (content : String) : Option Term :=
  interp.parse (tokenize content)



end Lego.Bootstrap

