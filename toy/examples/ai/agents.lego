-- agents.lego: AI Agents - A Unified Type Theory
-- All 8 types of LLMs unified under Cofree comonads
-- GPT, MoE, LRM, VLM, SLM, LAM, HLM, LCM - all are the same structure
--
-- The insight: Every AI agent is Cofree[F, A] where:
--   - A is the "annotation" (embeddings, activations, concepts)
--   - F is the "shape" (attention, routing, hierarchy)
--
-- Grammar = Implementation. This spec compiles to CUDA, ONNX, Metal.

lang Agents :=

-----------------------------------------------------
-- Tensor Types (compile-time shape checking)
-----------------------------------------------------
piece TensorType
  ttype ::= "Tensor" shape basetype
          | "Vec" number ttype
  shape ::= "[" "]" | "[" dims "]"
  dims ::= number | number "," dims
  basetype ::= "Float" | "Float16" | "Float32" | "Int" | "Int4"

-----------------------------------------------------
-- Embedding Types
-----------------------------------------------------
piece EmbeddingType
  embtype ::= "Embedding" number
            | "Attention" number number

-----------------------------------------------------
-- Attention Structure
-----------------------------------------------------
piece Attention
  attention ::= "(" "Attention" attfield ")"
  attfield ::= "d_model" number | "n_heads" number
             | "query" term | "key" term | "value" term | "output" term

-----------------------------------------------------
-- Universal Agent: Cofree[F, Embedding]
-----------------------------------------------------
piece CofreeAgent
  cofree ::= "(" "Cofree" functor term ")"
           | "(" "Agent" functor number ")"
  functor ::= "GPTLayer" | "MoELayer" | "LRMStep" | "VLMLayer"
            | "SLMLayer" | "LAMStep" | "HLMLayer" | "LCMLayer"

-----------------------------------------------------
-- Comonad Operations
-----------------------------------------------------
piece ComonadOps
  comonad ::= "(" "extract" term ")"
            | "(" "extend" term term ")"
            | "(" "duplicate" term ")"
            | "(" "fmap" term term ")"

-----------------------------------------------------
-- 1. GPT: Generative Pretrained Transformer
-----------------------------------------------------
piece GPTType
  gpt ::= "(" "GPT" number number ")"   -- d_model, n_layers

piece GPTLayer
  gptlayer ::= "(" "GPTLayer" gptfield ")"
  gptfield ::= "attention" term | "ffn" term | "next" maybeterm

piece GPTOps
  gptop ::= "(" "gpt_forward" term term ")"
          | "(" "causal_mask" number ")"
          | "(" "positional_encoding" term ")"
          | "(" "fold_layers" term term ")"

-----------------------------------------------------
-- 2. MoE: Mixture of Experts
-----------------------------------------------------
piece MoEType
  moe ::= "(" "MoE" number number number ")"  -- d_model, n_experts, n_layers

piece MoELayer
  moelayer ::= "(" "MoELayer" number moefield ")"
  moefield ::= "router" term | "experts" termlist | "selected" termlist

piece MoEOps
  moeop ::= "(" "route" term number ")"
          | "(" "moe_forward" term term ")"
          | "(" "load_balance_loss" term ")"
          | "(" "softmax" term ")"
          | "(" "top_k" number term ")"

-----------------------------------------------------
-- 3. LRM: Large Reasoning Model (with RAG)
-----------------------------------------------------
piece LRMType
  lrm ::= "(" "LRM" number ")"

piece LRMStep
  lrmstep ::= "(" "LRMStep" lrmfield ")"
  lrmfield ::= "thought" term | "retrieved" termlist
             | "next_step" maybeterm | "confidence" number

piece LRMOps
  lrmop ::= "(" "reason" term term ")"
          | "(" "rag" term term term ")"
          | "(" "chain_of_thought" term term ")"
          | "(" "refine" term ")"
          | "(" "decompose" term ")"

piece VectorDB
  vectordb ::= "(" "VectorDB" number ")"
             | "(" "db.search" term number ")"

-----------------------------------------------------
-- 4. VLM: Vision-Language Model
-----------------------------------------------------
piece VLMType
  vlm ::= "(" "VLM" number ")"

piece VLMLayer
  vlmlayer ::= "(" "VLMLayer" vlmfield ")"
  vlmfield ::= "vision" term | "language" term | "fused" term
             | "modality" modality
  modality ::= "Vision" | "Language" | "Fused"

piece VLMOps
  vlmop ::= "(" "vit" term ")"
          | "(" "cross_attention" term term ")"
          | "(" "vlm_forward" term term term ")"
          | "(" "split_patches" term number ")"
          | "(" "patch_embed" term ")"
          | "(" "embed_text" term ")"

-----------------------------------------------------
-- 5. SLM: Small Language Model
-----------------------------------------------------
piece SLMType
  slm ::= "(" "SLM" number number ")"  -- d_model, n_layers

piece SLMLayer
  slmlayer ::= "(" "SLMLayer" slmfield ")"
  slmfield ::= "grouped_query" term | "swiglu_ffn" term | "rope_pos" term

piece SLMOps
  slmop ::= "(" "grouped_query_attention" term term term ")"
          | "(" "swiglu" term ")"
          | "(" "rope" number term ")"
          | "(" "multi_head_attention" term term ")"

-----------------------------------------------------
-- 6. LAM: Large Action Model
-----------------------------------------------------
piece LAMType
  lam ::= "(" "LAM" number ")"

piece LAMStep
  lamstep ::= "(" "LAMStep" lamfield ")"
  lamfield ::= "observation" term | "action" action
             | "reward" number | "next_state" maybeterm

piece Action
  action ::= "(" "Click" point ")"
           | "(" "Type" string ")"
           | "(" "Scroll" direction ")"
           | "(" "Navigate" string ")"
           | "(" "APICall" string term ")"
  point ::= "(" number "," number ")"
  direction ::= "Up" | "Down" | "Left" | "Right"

piece LAMOps
  lamop ::= "(" "policy" term term ")"
          | "(" "act" term term ")"
          | "(" "react" term term term ")"
          | "(" "sample" term ")"
          | "(" "execute" term ")"

piece Environment
  env ::= "(" "Environment" envfield ")"
  envfield ::= "observe" | "step" term | "done"

-----------------------------------------------------
-- 7. HLM: Hierarchical Language Model
-----------------------------------------------------
piece HLMType
  hlm ::= "(" "HLM" number number ")"  -- d_upper, d_lower

piece HLMLayer
  hlmlayer ::= "(" "HLMLayer" hlmfield ")"
  hlmfield ::= "upper" term | "lower" term | "plan" termlist

piece HLMOps
  hlmop ::= "(" "plan" term term ")"
          | "(" "execute_plan" term term ")"
          | "(" "matryoshka" term term ")"
          | "(" "truncate" number term ")"
          | "(" "aggregate" term ")"

-----------------------------------------------------
-- 8. LCM: Large Concept Model
-----------------------------------------------------
piece LCMType
  lcm ::= "(" "LCM" number ")"

piece LCMLayer
  lcmlayer ::= "(" "LCMLayer" lcmfield ")"
  lcmfield ::= "concept" term | "instances" termlist | "relations" term

piece Concept
  concept ::= "(" "Concept" conceptfield ")"
  conceptfield ::= "embedding" term | "name" string
                 | "children" termlist | "parents" termlist

piece LCMOps
  lcmop ::= "(" "abstract" term term ")"
          | "(" "instantiate" term term ")"
          | "(" "analogy" term term term term ")"
          | "(" "nearest_concept" term term ")"

-----------------------------------------------------
-- Agent Transformations
-----------------------------------------------------
piece AgentTransform
  transform ::= "(" "AgentTransform" functor functor number number ")"
              | "(" "gpt_to_moe" term ")"
              | "(" "moe_to_lrm" term ")"
              | "(" "add_vision" term ")"

-----------------------------------------------------
-- Agent Composition
-----------------------------------------------------
piece AgentCompose
  compose ::= "(" ">>>" term term ")"     -- sequential
            | "(" "|||" term term ")"     -- parallel
            | "(" "branch" term term term ")"  -- conditional

-----------------------------------------------------
-- Universal Agent
-----------------------------------------------------
piece UniversalAgent
  universal ::= "(" "UniversalAgent" number ")"

-----------------------------------------------------
-- Complete Agent Example
-----------------------------------------------------
piece CompleteAgent
  complete ::= "(" "CompleteAgent" compfield ")"
  compfield ::= "vision" term | "reasoner" term | "actor" term

piece Process
  process ::= "(" "process" term term term ")"
            | "(" "needs_action" term ")"
            | "(" "generate_response" term ")"

-----------------------------------------------------
-- Compilation Targets
-----------------------------------------------------
piece CompileTarget
  target ::= "(" "compile_cuda" term ")"
           | "(" "compile_onnx" term ")"
           | "(" "compile_metal" term ")"
           | "(" "compile_webgpu" term ")"
           | "(" "trace" term ")"
           | "(" "cuda_codegen" term ")"
           | "(" "onnx_export" term ")"
           | "(" "metal_codegen" term ")"
           | "(" "wgsl_codegen" term ")"

-----------------------------------------------------
-- Tensor Operations
-----------------------------------------------------
piece TensorOps
  tensorop ::= "(" "matmul" term term ")"
             | "(" "transpose" term ")"
             | "(" "softmax" term ")"
             | "(" "scale" term ")"
             | "(" "concat" termlist ")"
             | "(" "mean" term ")"
             | "(" "sum" term ")"
             | "(" "generate" term ")"
             | "(" "project_q" term ")"
             | "(" "project_k" term ")"
             | "(" "project_v" term ")"

-----------------------------------------------------
-- Model Loading
-----------------------------------------------------
piece ModelLoad
  loadmodel ::= "(" "load_model" string ")"

-----------------------------------------------------
-- Helper types
-----------------------------------------------------
piece Helpers
  maybeterm ::= "Nothing" | "(" "Just" term ")"
  termlist ::= "[" "]" | "[" terms "]"
  terms ::= term | term "," terms

-----------------------------------------------------
-- Rules: Comonad Operations
-----------------------------------------------------
rule extract_cofree:
  (extract (Cofree $f $a $tail)) ~> $a

rule extend_cofree:
  (extend $f (Cofree $g $a $tail)) ~> (Cofree $g (app $f (Cofree $g $a $tail)) (fmap (extend $f) $tail))

rule duplicate_cofree:
  (duplicate (Cofree $f $a $tail)) ~> (Cofree $f (Cofree $f $a $tail) (fmap duplicate $tail))

-----------------------------------------------------
-- Rules: Attention
-----------------------------------------------------
rule attention_compute:
  (attention (Attention (query $q) (key $k) (value $v))) ~> (matmul (softmax (scale (matmul $q (transpose $k)))) $v)

rule scaled_dot_product:
  (scale (matmul $q $kt)) ~> (div (matmul $q $kt) (sqrt d_k))

-----------------------------------------------------
-- Rules: GPT
-----------------------------------------------------
rule gpt_forward:
  (gpt_forward (GPT $d $n) $input) ~> (extract (last (fold_layers $n (add $input (positional_encoding $input)))))

rule causal_mask:
  (causal_mask $n) ~> (generate (lambda (i j) (if (gte i j) 0.0 neg_inf)))

-----------------------------------------------------
-- Rules: MoE
-----------------------------------------------------
rule moe_route:
  (route $logits $k) ~> (normalize (take $k (sort_by_weight (indexed (softmax $logits)))))

rule moe_forward:
  (moe_forward $model $input) ~> (sum (map (lambda (i w) (mul w (app (get_expert $model i) $input))) (route (get_router $model) top_k)))

rule load_balance:
  (load_balance_loss $usage) ~> (sum (map (lambda (u) (pow (sub u target) 2)) $usage))

-----------------------------------------------------
-- Rules: LRM
-----------------------------------------------------
rule reason_step:
  (reason $query $model) ~> (unfold step (init $query $model))

rule rag_retrieve:
  (rag $db $query $model) ~> (last (reason (concat $query (db.search $db $query top_k)) $model))

rule chain_of_thought:
  (chain_of_thought $problem $model) ~> (compose (map (solve $model) (unfold decompose $problem)))

-----------------------------------------------------
-- Rules: VLM
-----------------------------------------------------
rule vit_encode:
  (vit $image) ~> (transformer (map patch_embed (split_patches $image patch_size)))

rule cross_attention:
  (cross_attention $vision $language) ~> (attention (Attention (query (project_q $language)) (key (project_k $vision)) (value (project_v $vision))))

rule vlm_forward:
  (vlm_forward $image $text $model) ~> (generate $model (cross_attention (vit $image) (embed_text $text)))

-----------------------------------------------------
-- Rules: SLM
-----------------------------------------------------
rule grouped_query:
  (grouped_query_attention $query $key $value) ~> (multi_head_attention $query (repeat groups (pair $key $value)))

rule swiglu:
  (swiglu $x) ~> (matmul W_down (hadamard (swish (matmul W_gate $x)) (matmul W_up $x)))

rule rope:
  (rope $pos $emb) ~> (add (hadamard $emb (cos (theta $pos))) (hadamard (rotate $emb) (sin (theta $pos))))

-----------------------------------------------------
-- Rules: LAM
-----------------------------------------------------
rule policy:
  (policy $state $model) ~> (categorical (softmax (action_head $model $state)))

rule act_loop:
  (act $env $model) ~> (loop (observe $env) $model)

rule react:
  (react $task $actor $reasoner) ~> (if (complete (execute (sample (policy (reason $task $reasoner) $actor)))) result (react (update $task result) $actor $reasoner))

-----------------------------------------------------
-- Rules: HLM
-----------------------------------------------------
rule hlm_plan:
  (plan $task $model) ~> (interface (upper_model $model) (forward (upper_model $model) $task))

rule hlm_execute:
  (execute_plan $model $subtasks) ~> (aggregate (map (forward (lower_model $model)) $subtasks))

rule matryoshka:
  (matryoshka $scales $emb) ~> (map (lambda (s) (truncate s $emb)) $scales)

-----------------------------------------------------
-- Rules: LCM
-----------------------------------------------------
rule abstract_concept:
  (abstract $instances $model) ~> (Concept (concept_head $model (mean $instances)))

rule instantiate_concept:
  (instantiate $concept $model) ~> (decoder $model (embedding $concept))

rule analogy:
  (analogy $a $b $c $model) ~> (nearest_concept $model (add (embedding $c) (sub (embedding $b) (embedding $a))))

-----------------------------------------------------
-- Rules: Agent Transformations
-----------------------------------------------------
rule gpt_to_moe:
  (gpt_to_moe $gpt) ~> (extend add_routing $gpt)

rule moe_to_lrm:
  (moe_to_lrm $moe) ~> (extend add_reasoning $moe)

rule add_vision:
  (add_vision $agent) ~> (extend fuse_modalities $agent)

-----------------------------------------------------
-- Rules: Composition
-----------------------------------------------------
rule sequential_compose:
  (>>> $a1 $a2) ~> (Cofree (compose_f $a1 $a2) (extract $a1) (fmap (>>> $a2) (unwrap $a1)))

rule parallel_compose:
  (||| $a1 $a2) ~> (Cofree (pair_f $a1 $a2) (merge (extract $a1) (extract $a2)) (pair (unwrap $a1) (unwrap $a2)))

rule branch_compose:
  (branch $pred $a1 $a2 $input) ~> (if (app $pred $input) (Left (app $a1 $input)) (Right (app $a2 $input)))

-----------------------------------------------------
-- Tests: Agent Types
-----------------------------------------------------
test "gpt_type": (GPT 768 12)
test "moe_type": (MoE 768 8 12)
test "lrm_type": (LRM 768)
test "vlm_type": (VLM 768)
test "slm_type": (SLM 512 6)
test "lam_type": (LAM 768)
test "hlm_type": (HLM 768 384)
test "lcm_type": (LCM 768)

-----------------------------------------------------
-- Tests: Cofree Structure
-----------------------------------------------------
test "agent_cofree": (Agent GPTLayer 768)
test "cofree_struct": (Cofree GPTLayer embedding tail)
test "extract": (extract (Cofree GPTLayer a tail)) ~~> a
test "extend": (extend f (Cofree GPTLayer a tail))
test "duplicate": (duplicate agent)

-----------------------------------------------------
-- Tests: Tensor Types
-----------------------------------------------------
test "tensor_1d": (Tensor [768] Float)
test "tensor_2d": (Tensor [32, 768] Float)
test "tensor_3d": (Tensor [8, 32, 64] Float16)
test "embedding": (Embedding 768)
test "attention": (Attention 768 12)

-----------------------------------------------------
-- Tests: GPT
-----------------------------------------------------
test "gpt_layer": (GPTLayer (attention attn) (ffn ff) (next (Just tok)))
test "gpt_forward": (gpt_forward (GPT 768 12) input)
test "causal_mask": (causal_mask 512)
test "positional": (positional_encoding input)

-----------------------------------------------------
-- Tests: MoE
-----------------------------------------------------
test "moe_layer": (MoELayer 8 (router logits) (experts [e1, e2, e3]) (selected [0, 2]))
test "route": (route logits 2)
test "moe_forward": (moe_forward model input)
test "load_balance": (load_balance_loss usage)

-----------------------------------------------------
-- Tests: LRM
-----------------------------------------------------
test "lrm_step": (LRMStep (thought t) (retrieved [r1, r2]) (confidence 0.9))
test "reason": (reason query model)
test "rag": (rag db query model)
test "chain_of_thought": (chain_of_thought problem model)
test "vectordb": (VectorDB 768)

-----------------------------------------------------
-- Tests: VLM
-----------------------------------------------------
test "vlm_layer": (VLMLayer (vision v) (language l) (fused f) (modality Fused))
test "modality_vision": Vision
test "modality_language": Language
test "modality_fused": Fused
test "vit": (vit image)
test "cross_attention": (cross_attention vision language)
test "vlm_forward": (vlm_forward image text model)

-----------------------------------------------------
-- Tests: SLM
-----------------------------------------------------
test "slm_layer": (SLMLayer (grouped_query gq) (swiglu_ffn sw) (rope_pos rp))
test "grouped_query_attn": (grouped_query_attention q k v)
test "swiglu": (swiglu x)
test "rope": (rope 42 embedding)

-----------------------------------------------------
-- Tests: LAM
-----------------------------------------------------
test "lam_step": (LAMStep (observation obs) (action (Click (100, 200))) (reward 1.0))
test "action_click": (Click (100, 200))
test "action_type": (Type "hello world")
test "action_scroll": (Scroll Down)
test "action_navigate": (Navigate "https://example.com")
test "action_api": (APICall "/api/data" params)
test "policy": (policy state model)
test "act": (act env model)
test "react": (react task actor reasoner)

-----------------------------------------------------
-- Tests: HLM
-----------------------------------------------------
test "hlm_layer": (HLMLayer (upper u) (lower l) (plan [s1, s2, s3]))
test "hlm_plan": (plan task model)
test "hlm_execute": (execute_plan model subtasks)
test "matryoshka": (matryoshka [64, 128, 256, 512] embedding)

-----------------------------------------------------
-- Tests: LCM
-----------------------------------------------------
test "lcm_layer": (LCMLayer (concept c) (instances [i1, i2]) (relations graph))
test "concept": (Concept (embedding e) (name "vehicle") (children [car, truck]) (parents [object]))
test "abstract": (abstract instances model)
test "instantiate": (instantiate concept model)
test "analogy": (analogy king man queen model)

-----------------------------------------------------
-- Tests: Transformations
-----------------------------------------------------
test "gpt_to_moe": (gpt_to_moe gpt_model)
test "moe_to_lrm": (moe_to_lrm moe_model)
test "add_vision": (add_vision agent)
test "transform": (AgentTransform GPTLayer MoELayer 768 768)

-----------------------------------------------------
-- Tests: Composition
-----------------------------------------------------
test "sequential": (>>> model1 model2)
test "parallel": (||| vision_model language_model)
test "branch": (branch pred agent1 agent2)
test "vision_reasoner": (||| (VLM 768) (LRM 768))
test "hierarchical_moe": (>>> (HLM 768 768) (MoE 768 8 12))

-----------------------------------------------------
-- Tests: Complete Agent
-----------------------------------------------------
test "complete_agent": (CompleteAgent (vision vit) (reasoner lrm) (actor lam))
test "process": (process image query agent)

-----------------------------------------------------
-- Tests: Compilation
-----------------------------------------------------
test "compile_cuda": (compile_cuda agent)
test "compile_onnx": (compile_onnx agent)
test "compile_metal": (compile_metal agent)
test "compile_webgpu": (compile_webgpu agent)

-----------------------------------------------------
-- Tests: Tensor Ops
-----------------------------------------------------
test "matmul": (matmul a b)
test "transpose": (transpose matrix)
test "softmax": (softmax logits)
test "concat": (concat [t1, t2, t3])
test "mean": (mean tensors)

-----------------------------------------------------
-- Tests: Model Loading
-----------------------------------------------------
test "load_vit": (load_model "vit-base")
test "load_reasoning": (load_model "reasoning-7b")
test "load_action": (load_model "action-model")

-- =============================================================================
-- AI Agents Checklist
-- =============================================================================
-- [x] Grammar: All 8 agent types (GPT, MoE, LRM, VLM, SLM, LAM, HLM, LCM)
-- [x] Grammar: Cofree comonad structure
-- [x] Grammar: Agent composition (sequential, parallel, branch)
-- [x] Grammar: Agent transformations
-- [x] Grammar: Compilation targets
-- [x] Rules: Comonad operations (extract, extend, duplicate)
-- [x] Rules: Attention mechanism
-- [x] Rules: Each agent type forward pass
-- [x] Rules: Agent transformations
-- [x] Rules: Composition operators
-- [ ] Full agent semantics (needs tensor runtime)
-- Keywords: cuts := ["piece", "rule", "test", "def"]
-- =============================================================================

-- THE GRAND UNIFICATION:
-- All 8 LLM types share the same structure:
--
--   GPT  = Cofree (Sequential)    Embedding  -- Autoregressive
--   MoE  = Cofree (Routing n)     Embedding  -- Expert selection
--   LRM  = Cofree (Reasoning)     Embedding  -- Chain-of-thought
--   VLM  = Cofree (Multimodal)    Embedding  -- Vision + Language
--   SLM  = Cofree (Efficient)     Embedding  -- Compressed
--   LAM  = Cofree (Action)        Embedding  -- Environment interaction
--   HLM  = Cofree (Hierarchical)  Embedding  -- Multi-scale
--   LCM  = Cofree (Conceptual)    Embedding  -- Abstract reasoning
--
-- The Cofree comonad provides:
--   - extract: Get current representation
--   - extend:  Propagate computation
--   - fmap:    Transform structure
--
-- Grammar = Implementation.
-- One spec, all agents, all platforms.
